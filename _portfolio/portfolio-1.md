---
title: "Portfolio item number 1"
excerpt: "Short description of portfolio item number 1<br/><img src='/images/500x300.png'>"
collection: portfolio
---
<div style="width:100%;margin-left:0px;margin-right:0px;margin-top:10px; flex-wrap:wrap-reverse; " class="table-like " onmouseout="gif_stop('rlvlmf_image', 'rlvlmf_gif')" onmouseover="gif_start('rlvlmf_image', 'rlvlmf_gif')">
<div class="zero" style="flex: 1 0 270px;margin-top:0px;margin-right:20px;max-width:270px;">
<div class="one">
<img id="rlvlmf_gif" src="images/rlvlmf_before.png" class="paper_img">
</div>
<!-- -->
</div>
<div style="flex: 10000 1 400px;margin-bottom:10px;" valign="top">
<p class="paper_title" style="margin-top:0em;"><a><papertitle>RL-VLM-F: Reinforcement Learning from Vision Language Foundation Model Feedback</papertitle></a>
<br>
<a class="black_link" href="https://yufeiwang63.github.io/">Yufei Wang</a>,
<a class="black_link">Zhanyi Sun</a>,
<strong><u>Jesse Zhang</u></strong>,
<a class="black_link" href="https://www.zhou-xian.com/">Zhou Xian</a>,
<a class="black_link" href="https://ebiyik.github.io/">Erdem Bıyık</a>,
<a class="black_link" href="https://davidheld.github.io/">David Held</a>,
<a class="black_link" href="https://zackory.com/">Zackory Erickson</a>
<br>
<font color="Gray"><i>Submitted to ICML 2024</i></font>
<br>
<a href="https://arxiv.org/abs/2402.03681">arXiv</a>
</p>
<p style="margin-bottom:0em;">We propose to use Vision-Language Models (VLMs) to generate preferences for RLHF instead of humans. We call this RL-VLM-F, and we demonstrate that RL-VLM-F allows agents to learn arbitrary new tasks from VLMs without any human feedback.</p>
</div>
</div>
