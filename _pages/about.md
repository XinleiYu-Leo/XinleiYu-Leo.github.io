---
permalink: /
title: "Xinlei Yu (Leo)"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Xinlei is a research assistant at the HaVRI Lab, advised by Dr. Heather Culbertson at the University of Southern California. He recently graduated with an MS in Computer Engineering from the same institution. His research interests include human-computer interaction, haptics, and drones.

Before this, he worked in the Brain-Body Dynamics Lab, advised by Dr. Francisco Valero-Cuevas, where he developed a computer vision-based Infant Motor Learning Assistant Toy to study whether babies can learn to control their bodies while on their tummies. Previously, Xinlei graduated from Iowa State University with a B.S. in Computer Engineering in December 2021.






# On-going Project

<table>
<tr>
<td style="width:40%">
<img src="https://raw.githubusercontent.com/XinleiYu-Leo/XinleiYu-Leo.github.io/master/images/object2" alt="teaser" height="200" width="800"/>
</td>
<td style="width:60%">
Working on end-to-end drone-based navigation devices that enable users to navigate in indoor environments with haptic feedback.  <br>
The image capture demonstrates real-time object detection from a drone camera*
<br>
</td>
</tr>
</table>
<br>
<br>

# Under Review

<table>
<tr>
<td style="width:40%">
<img src="https://raw.githubusercontent.com/XinleiYu-Leo/XinleiYu-Leo.github.io/master/images/crazy_teaser_new.png" alt="teaser" height="200" width="800"/>
</td>
<td style="width:60%">
<strong>CrazyJoystick: A Handheld Flyable Joystick for Providing On-Demand Haptic Feedback in Virtual Reality</strong> <br>
Submitted to ACM SIGCHI 2025 
<br><br>
Yang Chen*, <strong>Xinlei Yu*</strong>, and Heather Culbertson
<br><br>
</td>
</tr>
</table>

<br>
<br>

# Research Project 

<table>
<tr>
<td style="width:40%">
<img src="https://raw.githubusercontent.com/XinleiYu-Leo/Xinlei-leo.github.io/master/assets/images/talk_SCR.png" alt="drawing" height="200" width="400"/>
</td>
<td style="width:60%">
<strong>Exploring Electrotactile Stimulation as a Modality for Sensation Illusion on the Arm:</strong> Presented at the recent <a href="https://sites.uci.edu/scr2023/schedule/">SCR'23</a>
<br><br>
<strong>Xinlei Yu</strong>, Xin Zhu, Xiaopan Zhang and Heather Culbertson
<br><br>
<a href="https://bpb-us-e2.wpmucdn.com/sites.uci.edu/dist/2/5230/files/2023/09/66_SCR_23_Xinlei_Yu.pdf">[abstract]</a>
</td>
</tr>
<tr>
<td style="width:40%">
<img src="https://raw.githubusercontent.com/XinleiYu-Leo/Xinlei-leo.github.io/master/assets/images/3T_Demo_DARE-Cover.jpg" alt="drawing" height="200" width="400"/>
</td>
<td style="width:60%">
<strong>Tummy Time Toy</strong>: An Infant Learning Toy
<br>
<br><br>
<strong>Xinlei Yu</strong>, Arya Salgaonkar, Stacey Dusing and Francisco Valero-Cuevas
<br><br>
<a href="https://youtu.be/6PznLd5wy5c">[Demo Video]</a> <a href="https://youtu.be/JgYYosFgYtE">[Pilot Study Video]</a>
</td>
</tr>
</table>


<br>

# Fun Project 

<table>
<tr>
<td style="width:40%">
<img src="https://raw.githubusercontent.com/XinleiYu-Leo/XinleiYu-Leo.github.io/master/images/handtrackingDrone.drawio.png" alt="System Image" height="400" width="450" />
</td>
<td style="width:60%">
<strong>Gesture-based Controlled Crazyflie Hand Tracking System</strong>
<br>
<a href="https://youtube.com/shorts/QBKCI4z-H1E?feature=share">[Demo Video]</a> <a href="https://raw.githubusercontent.com/XinleiYu-Leo/XinleiYu-Leo.github.io/master/images/handtrackingDrone.drawio.png">[System Diagram]</a> 
</td>
</tr>
<tr>
<td style="width:40%">
<img src="https://raw.githubusercontent.com/XinleiYu-Leo/XinleiYu-Leo.github.io/master/images/VR_DressingRoom.png" alt="VR Room Image" height="300" width="450" />
</td>
<td style="width:60%">
<strong>VR Dressing Room</strong>
<br>
<a href="https://youtube.com/shorts/3uVC-7T6mHI?feature=share">[Demo Video]</a>
</td>
</tr>
</table>

<br>

# Past Research Project (selected)

<table>
  <tr>
    <td style="width:40%">
      <img src="https://raw.githubusercontent.com/XinleiYu-Leo/Xinlei-leo.github.io/master/assets/images/electro_diagram.png" alt="drawing2" height="250" width="500"/>
    </td>
    <td style="width:60%">
      <strong>TactileNet: Multi-armed bandit-based calibration for Electro-tactile Simulation:</strong> Developed an electro-tactile display with a Sensory PCI card and a group of power sources and amplifiers and designed a multi-armed bandit-based calibration method to find an optimal signal parameter for pleasant stimulation.
      <br><br>
      <a href="https://github.com/xinleiyuUSC/MAB_UCB">[Github(partially available)]</a>
    </td>
  </tr>
  <!--<tr>
    <td style="width:40%">
      <img src="https://raw.githubusercontent.com/XinleiYu-Leo/Xinlei-leo.github.io/master/assets/images/TTT.png" alt="drawing2" height="200" width="400"/>
    </td>
    <td style="width:60%">
      <strong>Tummy Time Toy:</strong> A computer vision-based infant motor learning assistant toy (under US Patent review). This interactive toy rewards infants with lights and music when they lift their heads past a certain threshold, encouraging the development of prone motor skills. The primary goal is to study whether babies can learn to control their bodies during tummy time with the toy's assistance, aiding in muscle control and increasing their tolerance for tummy time.
      <br><br>
      <a href="https://youtu.be/6PznLd5wy5c">[video]</a> [Github(available soon)]
    </td>
  </tr> -->
  <tr>
    <td style="width:40%">
      <img src="https://raw.githubusercontent.com/XinleiYu-Leo/Xinlei-leo.github.io/master/assets/images/ASL.jpg" alt="drawing3" height="200" width="400"/>
    </td>
    <td style="width:60%">
      <strong>American Sign Language:</strong> we present an alphabet translator for American Sign Language (ASL), deploying Convolutional Neural Networks (CNN) and Residual Neural Networks (ResNet) to classify RGB images of ASL alphabet hand gestures. We meticulously tuned hyperparameters to ensure high training accuracy and solid test performance.
      <br><br>
      <a href="https://raw.githubusercontent.com/XinleiYu-Leo/Xinlei-leo.github.io/master/assets/ASL_Paper.pdf">[paper]</a> <a href="https://github.com/xinleiyuUSC/ASL_Project/tree/main">[Github]</a>
    </td>
  </tr>
</table>
